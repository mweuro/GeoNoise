{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(\"../data_to_train/tensors.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "])\n",
    "\n",
    "class TransformedDataset(Dataset):\n",
    "    def __init__(self, dataset, transform):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.dataset[idx]\n",
    "        x = self.transform(x)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = []\n",
    "labels_list = []\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    feature_map = data[i, :, :, 1:].permute(2, 0, 1)\n",
    "    labels = data[i, :, :, 0]\n",
    "    label = labels.mean()\n",
    "    features_list.append(feature_map)\n",
    "    labels_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th percentile: 43.14\n",
      "50th percentile: 50.984\n",
      "75th percentile: 55.599999999999994\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "q25 = np.quantile(labels_list, 0.25)\n",
    "q50 = np.quantile(labels_list, 0.5)\n",
    "q75 = np.quantile(labels_list, 0.75)\n",
    "\n",
    "print(\"25th percentile:\", q25)\n",
    "print(\"50th percentile:\", q50)\n",
    "print(\"75th percentile:\", q75)\n",
    "\n",
    "def quantize(value):\n",
    "    if value <= q25:\n",
    "        return 0\n",
    "    elif value <= q50:\n",
    "        return 1\n",
    "    elif value <= q75:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "\n",
    "quantized_labels = [quantize(x) for x in labels_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 400\n",
      "Validation dataset size: 114\n",
      "Test dataset size: 57\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(features_list = features_list, labels_list = quantized_labels):\n",
    "    labels = torch.tensor(labels_list)\n",
    "    features = torch.stack(features_list)\n",
    "    dataset = TensorDataset(features, labels)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def train_val_test_split(dataset):\n",
    "    return random_split(dataset, [0.7, 0.2, 0.1])\n",
    "\n",
    "\n",
    "dataset = create_dataset()\n",
    "train_dataset, val_dataset, test_dataset = train_val_test_split(dataset)\n",
    "train_dataset = TransformedDataset(train_dataset, transform)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(\"Train dataset size:\", len(train_dataset))\n",
    "print(\"Validation dataset size:\", len(val_dataset))\n",
    "print(\"Test dataset size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 32.,  12.,  17.,  12.,  15.,  17.,  72., 145., 188.,  61.]),\n",
       " array([ 0.688 ,  7.1488, 13.6096, 20.0704, 26.5312, 32.992 , 39.4528,\n",
       "        45.9136, 52.3744, 58.8352, 65.296 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(labels_list, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 3 * 3, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  # (16, 12, 12)\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  # (32, 6, 6)\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))  # (64, 3, 3)\n",
    "        x = x.view(-1, 64 * 3 * 3)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def _train(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for inputs, labels in tqdm(dataloader, desc = \"Training\", leave = False):\n",
    "        inputs, labels = inputs.float().to(device), labels.to(device)\n",
    "\n",
    "        # Forward\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        all_preds.extend(torch.argmax(outputs, dim = 1).cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    return total_loss / len(dataloader), accuracy\n",
    "\n",
    "\n",
    "\n",
    "def _validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc = \"Validation\", leave = False):\n",
    "            inputs, labels = inputs.float().to(device), labels.to(device)\n",
    "\n",
    "            # Forward\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            all_preds.extend(torch.argmax(outputs, dim = 1).cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    return total_loss / len(dataloader), accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_epochs, train_loader, test_loader, device, patience = np.inf):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    best_acc = 0\n",
    "    best_epoch = 0\n",
    "    max_epoch = 0\n",
    "    is_quit = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = _train(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc = _validate(model, test_loader, criterion, device)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        max_epoch += 1\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_epoch = epoch\n",
    "            is_quit = 0\n",
    "            torch.save(model.state_dict(), 'model/best_model.pth')\n",
    "        else:\n",
    "            is_quit += 1\n",
    "            \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "            print(f\"Train Loss: {train_loss:.4f},\\\n",
    "                    Train Accuracy: {train_acc:.4f}\")\n",
    "            print(f\"Val Loss: {val_loss:.4f},\\\n",
    "                    Val Accuracy: {val_acc:.4f}\")\n",
    "            print(\"-\" * 50)\n",
    "        \n",
    "        if is_quit > patience:\n",
    "            break\n",
    "    print(f\"BEST EPOCH: {best_epoch:.2f}\\\n",
    "          BEST ACCURACY: {val_accs[best_epoch]:.2f}\")\n",
    "    \n",
    "    return [*range(1, max_epoch + 1)], train_losses, val_losses, train_accs, val_accs, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "Train Loss: 1.0989,                    Train Accuracy: 0.5350\n",
      "Val Loss: 1.0283,                    Val Accuracy: 0.4737\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "Train Loss: 1.0461,                    Train Accuracy: 0.5375\n",
      "Val Loss: 1.0043,                    Val Accuracy: 0.5877\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "Train Loss: 1.0069,                    Train Accuracy: 0.5700\n",
      "Val Loss: 1.0215,                    Val Accuracy: 0.5965\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "Train Loss: 0.9582,                    Train Accuracy: 0.5900\n",
      "Val Loss: 0.9756,                    Val Accuracy: 0.5789\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "Train Loss: 0.9190,                    Train Accuracy: 0.5875\n",
      "Val Loss: 1.0387,                    Val Accuracy: 0.5263\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "Train Loss: 0.8366,                    Train Accuracy: 0.6300\n",
      "Val Loss: 1.0090,                    Val Accuracy: 0.5702\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "Train Loss: 0.9044,                    Train Accuracy: 0.6125\n",
      "Val Loss: 0.9904,                    Val Accuracy: 0.6404\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "Train Loss: 0.8002,                    Train Accuracy: 0.6725\n",
      "Val Loss: 1.2320,                    Val Accuracy: 0.5175\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "Train Loss: 0.8651,                    Train Accuracy: 0.6250\n",
      "Val Loss: 1.0201,                    Val Accuracy: 0.5965\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "Train Loss: 0.7748,                    Train Accuracy: 0.6575\n",
      "Val Loss: 1.0347,                    Val Accuracy: 0.6316\n",
      "--------------------------------------------------\n",
      "BEST EPOCH: 34.00          BEST ACCURACY: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "model = CNNClassifier(num_classes=4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "n_epochs = 50\n",
    "epochs, train_losses, val_losses, train_accs, val_accs, best_epoch = train_model(model, criterion, optimizer, n_epochs, train_loader, val_loader, \"cpu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
