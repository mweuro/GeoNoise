{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(\"tensors3.pt\")\n",
    "# data[100, :, :, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = []\n",
    "labels_list = []\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    feature_map = data[i, :, :, 1:].permute(2, 0, 1)\n",
    "    labels = data[i, :, :, 0]\n",
    "    label = labels.mean()\n",
    "    features_list.append(feature_map)\n",
    "    labels_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th percentile: 43.14\n",
      "50th percentile: 50.984\n",
      "75th percentile: 55.599999999999994\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "q25 = np.quantile(labels_list, 0.25)\n",
    "q50 = np.quantile(labels_list, 0.5)\n",
    "q75 = np.quantile(labels_list, 0.75)\n",
    "\n",
    "print(\"25th percentile:\", q25)\n",
    "print(\"50th percentile:\", q50)\n",
    "print(\"75th percentile:\", q75)\n",
    "\n",
    "def quantize(value):\n",
    "    if value <= q25:\n",
    "        return 0\n",
    "    elif value <= q50:\n",
    "        return 1\n",
    "    elif value <= q75:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "\n",
    "quantized_labels = [quantize(x) for x in labels_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 519\n",
      "Validation dataset size: 26\n",
      "Test dataset size: 26\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(features_list = features_list, labels_list = quantized_labels):\n",
    "    labels = torch.tensor(labels_list)\n",
    "    features = torch.stack(features_list)\n",
    "    dataset = TensorDataset(features, labels)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def train_val_test_split(dataset, val_indices, test_indices):\n",
    "    all_indices = set(range(len(dataset)))\n",
    "    train_indices = list(all_indices - set(val_indices) - set(test_indices))\n",
    "    train_indices.sort()\n",
    "    train_dataset = Subset(dataset, train_indices)\n",
    "    val_dataset = Subset(dataset, val_indices)\n",
    "    test_dataset = Subset(dataset, test_indices)\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "\n",
    "dataset = create_dataset()\n",
    "val_indices = [20, 33, 52, 71, 90, 110, 132, 155, 177, 197, 219, 237, 250, 257, 22, 39, 58, 77, 96, 116, 138, 161, 183, 203, 225, 243]\n",
    "test_indices = [21, 34, 53, 72, 91, 111, 133, 154, 178, 198, 220, 238, 251, 258, 23, 40, 59, 78, 97, 117, 139, 162, 184, 204, 226, 244]\n",
    "train_dataset, val_dataset, test_dataset = train_val_test_split(dataset, val_indices, test_indices)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"Train dataset size:\", len(train_dataset))\n",
    "print(\"Validation dataset size:\", len(val_dataset))\n",
    "print(\"Test dataset size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 32.,  12.,  17.,  12.,  15.,  17.,  72., 145., 188.,  61.]),\n",
       " array([ 0.688 ,  7.1488, 13.6096, 20.0704, 26.5312, 32.992 , 39.4528,\n",
       "        45.9136, 52.3744, 58.8352, 65.296 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(labels_list, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(23.3200, dtype=torch.float64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_list[0].shape\n",
    "labels_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        # self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(32 * 3 * 3, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # (16, 12, 12)\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # (32, 6, 6)\n",
    "        # x = self.pool(F.relu(self.conv3(x)))  # (64, 3, 3)\n",
    "        x = x.view(-1, 32 * 3 * 3)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def _train(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for inputs, labels in tqdm(dataloader, desc = \"Training\", leave = False):\n",
    "        inputs, labels = inputs.float().to(device), labels.to(device)\n",
    "\n",
    "        # Forward\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        all_preds.extend(torch.argmax(outputs, dim = 1).cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    return total_loss / len(dataloader), accuracy\n",
    "\n",
    "\n",
    "\n",
    "def _validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc = \"Validation\", leave = False):\n",
    "            inputs, labels = inputs.float().to(device), labels.to(device)\n",
    "\n",
    "            # Forward\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            all_preds.extend(torch.argmax(outputs, dim = 1).cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    return total_loss / len(dataloader), accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_epochs, train_loader, test_loader, device, patience = np.inf):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    best_acc = 0\n",
    "    best_epoch = 0\n",
    "    max_epoch = 0\n",
    "    is_quit = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = _train(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc = _validate(model, test_loader, criterion, device)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        max_epoch += 1\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_epoch = epoch\n",
    "            is_quit = 0\n",
    "        else:\n",
    "            is_quit += 1\n",
    "            \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "            print(f\"Train Loss: {train_loss:.4f},\\\n",
    "                    Train Accuracy: {train_acc:.4f}\")\n",
    "            print(f\"Val Loss: {val_loss:.4f},\\\n",
    "                    Val Accuracy: {val_acc:.4f}\")\n",
    "            print(\"-\" * 50)\n",
    "        \n",
    "        if is_quit > patience:\n",
    "            break\n",
    "    print(f\"BEST EPOCH: {best_epoch:.2f}\\\n",
    "          BEST ACCURACY: {val_accs[best_epoch]:.2f}\")\n",
    "    \n",
    "    return [*range(1, max_epoch + 1)], train_losses, val_losses, train_accs, val_accs, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (128) to match target batch_size (32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m epochs, train_losses, val_losses, train_accs, val_accs, best_epoch \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[82], line 68\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, num_epochs, train_loader, test_loader, device, patience)\u001b[0m\n\u001b[1;32m     65\u001b[0m is_quit \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 68\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     val_loss, val_acc \u001b[38;5;241m=\u001b[39m _validate(model, test_loader, criterion, device)\n\u001b[1;32m     70\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[82], line 15\u001b[0m, in \u001b[0;36m_train\u001b[0;34m(model, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Forward\u001b[39;00m\n\u001b[1;32m     14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m---> 15\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Backward\u001b[39;00m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/venvy/spatial/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvy/spatial/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/venvy/spatial/lib/python3.10/site-packages/torch/nn/modules/loss.py:1295\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvy/spatial/lib/python3.10/site-packages/torch/nn/functional.py:3494\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3493\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3495\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3501\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (128) to match target batch_size (32)."
     ]
    }
   ],
   "source": [
    "model = CNNClassifier(num_classes=4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs, train_losses, val_losses, train_accs, val_accs, best_epoch = train_model(model, criterion, optimizer, 100, train_loader, val_loader, \"cpu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
